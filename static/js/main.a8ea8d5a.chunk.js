(window.webpackJsonp=window.webpackJsonp||[]).push([[0],{123:function(e,n,t){e.exports=t(355)},128:function(e,n,t){},130:function(e,n,t){},355:function(e,n,t){"use strict";t.r(n);var o=t(0),a=t.n(o),i=t(17),r=t.n(i),c=(t(128),t(66)),l=t(46),s=t(48),p=t(47),u=t(36),h=t(49),v=t(35),d=(t(6),t(21)),f=t.n(d),g=t(15),m=t.n(g),C=(t(130),t(120)),x=t(37),y=t(121);function L(){var e=Object(C.a)(['\n    // TODO turn this into its own .frag file.\n      precision highp float;\n      float PI = 3.14159265358979323846264338327950288419716939937510;\n      vec2 SET_TO_TRANSPARENT = vec2(-1.0, -1.0);\n      vec4 TRANSPARENT_PIXEL = vec4(0.0, 0.0, 0.0, 0.0);\n      bool FISHEYE_RADIAL_CORRECTION = true;\n      uniform float correction1, correction2, correction3, correction4, cropTop, cropBottom, cropLeft, cropRight, xCenter, yCenter;\n      uniform sampler2D InputTexture;\n      uniform float pitch, roll, yaw, fovIn, fovOut, x, y, z;\n      uniform int inputProjection, outputProjection, gridLines, solidAngle, width, height;\n      uniform float test;\n      varying vec2 uv;\n      bool isTransparent = false; // A global flag indicating if the pixel should just set to transparent and return immediately. \n      const int EQUI = 0;\n      const int FISHEYE = 1;\n      const int FLAT = 2;\n      const int CUBEMAP = 3;\n      const int GRIDLINES_OFF = 0;\n      const int GRIDLINES_ON = 1;\n\n      // uniform vec3 InputRotation;\n      // A transformation matrix rotating about the x axis by th degrees.\n      mat3 Rx(float th)\n      {\n          return mat3(1, 0, 0,\n                      0, cos(th), -sin(th),\n                      0, sin(th), cos(th));\n      }\n      // A transformation matrix rotating about the y axis by th degrees.\n      mat3 Ry(float th)\n      {\n          return mat3(cos(th), 0, sin(th),\n                         0,    1,    0,\n                      -sin(th), 0, cos(th));\n      }\n      // A transformation matrix rotating about the z axis by th degrees.\n      mat3 Rz(float th)\n      {\n          return mat3(cos(th), -sin(th), 0,\n                      sin(th),  cos(th), 0,\n                        0,         0   , 1);\n      }\n\n      // Rotate a point vector by th.x then th.y then th.z, and return the rotated point.\n      // TODO I\'m abusing this function rather than just writing pointToSphericalCoordinates\n      // Find instances where this can be simplified.\n      vec3 rotatePoint(vec3 p, vec3 th)\n      {\n        return Rx(th.x) * Ry(th.y) * Rz(th.z) * p;\n      }\n\n      // Convert a 3D point on the unit sphere into latitude and longitude.\n      // In more mathy terms we\'re converting from "Cartesian Coordinates" to "Spherical Coordinates"\n      vec2 pointToLatLon(vec3 point)\n      {\n        float r = distance(vec3(0.0, 0.0, 0.0), point);\n        vec2 latLon;\n        latLon.x = asin(point.z / r);\n        latLon.y = atan(point.x, point.y);\n        return latLon;\n      }\n\n      // Convert latitude, longitude into a 3d point on the unit-sphere.\n      // In more mathy terms we\'re converting from  "Spherical Coordinates" to "Cartesian Coordinates"\n      vec3 latLonToPoint(vec2 latLon)\n      {\n          float lat = latLon.x;\n          float lon = latLon.y;\n          vec3 point;\n          point.x = cos(lat) * sin(lon);\n          point.y = cos(lat) * cos(lon);\n          point.z = sin(lat);\n          return point;\n      }\n\n      // Convert pixel coordinates from an Equirectangular image into latitude/longitude coordinates.\n      vec2 equiUvToLatLon(vec2 local_uv)\n      {\n          return vec2(local_uv.y * PI - PI/2.0,\n                      local_uv.x * 2.0*PI - PI);\n      }\n\n      // Apply radial correction to a 3D point.\n      vec3 pointRadialCorrection(vec3 point) \n      {\n        // Rotate the point so that latitude corresponds with the center of the frame.\n        // We could do it without rotation, by reimplementing pointToLatLon\n        vec3 rotation = vec3(-PI/2.0, 0.0, 0.0);\n        point = rotatePoint(point, rotation);\n        // Get the calibration parameters\n        vec4 fishCorrect = vec4(correction1, correction2, correction3, correction4);\n        // vec4 fishCorrect = vec4(-0.0835, -0.021129, 0.0303, -0.16599);\n        // fishCorrect.xyzw -= 1.0;\n        // Get the longitude\n        vec2 latLon = pointToLatLon(point);\n        // Get the radius of the point in the xy plane\n        float r = distance(point.xy, vec2(0.0, 0.0));\n        // Apply the calibration parameters\n        r += r * (fishCorrect.x + r * (fishCorrect.y + r * (fishCorrect.z + r * fishCorrect.w)));\n        point.x = r * sin(latLon.y);\n        point.y = r * cos(latLon.y);\n        // Make sure the point is back on the unit sphere\n        point = normalize(point);\n        return rotatePoint(point, -rotation);\n      }\n      // Convert  pixel coordinates from an Fisheye image into 3D point.\n      vec3 fisheyeUvToPoint(vec2 local_uv, float fovOutput)\n      {\n        \n        vec2 pos = 2.0 * local_uv - 1.0;\n        // The distance from the source pixel to the center of the image\n        float r = distance(vec2(0.0,0.0),pos.xy);\n        // Don\'t bother with pixels outside of the fisheye circle\n        if (1.0 < r) {\n          isTransparent = true;\n          return vec3(0.0, 0.0, 0.0);\n        }\n        float theta = atan(r, 1.0);\n        r = tan(theta/fovOutput);\n        vec2 latLon;\n        latLon.x = (1.0 - r) * (PI/2.0);\n        // Calculate longitude\n        latLon.y = PI + atan(-pos.x, pos.y);\n          \n        if (latLon.y < 0.0) {\n          latLon.y += 2.0*PI;\n        }\n        vec3 point = latLonToPoint(latLon);\n        point =  normalize(point);\n        point = rotatePoint(point, vec3(PI/2.0, 0.0, 0.0));\n        return point;\n      }\n\n      // Convert  pixel coordinates from an Fisheye image into latitude/longitude coordinates.\n      vec2 fisheyeUvToLatLon(vec2 local_uv, float fovOutput)\n      {\n        vec3 point = fisheyeUvToPoint(local_uv, fovOutput);\n        vec2 latLon = pointToLatLon(point);\n        return latLon;\n      }\n\n      // Convert a cubemap uv to a 3d point on a unit cube\n      vec3 cubemapUvToPoint(vec2 local_uv)\n      {\n        float verticalBoundary = 0.5;\n        float leftBoundary  = 1.0/3.0;\n        float rightBoundary = 2.0/3.0;\n        // Position of the source pixel in uv coordinates in the range [-1,1]\n        vec2 pos = (2.0 * local_uv) - 1.0;\n        vec3 point;\n        float faceDistance = fovOut / 3.0;\n        // Is it a standard cubemap or an EAC?\n        // Link for more details: https://blog.google/products/google-ar-vr/bringing-pixels-front-and-center-vr-video/\n        bool equiAngularCubemap = true;\n        // Remove overlap in the image.\n        float verticalCorrection = 2.0/3.0;\n        // No idea why this was needed, but ~1.15 seems to work and pi / e is really close.\n        float piDividedByE = 1.155727349790921717910093183312696299120851023164415820499;\n        // The faces of the cubemap. To explain I\'ll define the following:\n        // Let\'s call +X: "Right"\n        //            -X: "Left"\n        //            +Y: "Forward"\n        //            -Y: "Back"\n        //            +Z: "Up"\n        //            -Z: "Down"\n        // Top left face in output image\n        if (local_uv.x <= leftBoundary && verticalBoundary <= local_uv.y) {\n          pos += vec2(2.0/3.0, -0.5);\n          if(equiAngularCubemap)  {\n            pos = tan(pos*PI/2.0)/2.0;\n            pos.x *= piDividedByE;\n          }\n          // "Left" face of cube\n          point = vec3(-faceDistance, pos.x, verticalCorrection*pos.y);\n        }\n        // Top Middle Face in output image\n        else if (leftBoundary < local_uv.x && local_uv.x <= rightBoundary && verticalBoundary <= local_uv.y) {\n          pos += vec2(0.0, -0.5);\n          if(equiAngularCubemap)  {\n            pos = tan(pos*PI/2.0)/2.0;\n            pos.x *= piDividedByE;\n          }\n          // "Front" face of cube \n          point = vec3(pos.x, faceDistance, verticalCorrection*pos.y);\n        }\n        // Top Right Face in output image\n        else if (rightBoundary < local_uv.x && verticalBoundary <= local_uv.y) {\n          pos += vec2(-2.0/3.0, -0.5);\n          if(equiAngularCubemap)  {\n            pos = tan(pos*PI/2.0)/2.0;\n            pos.x *= piDividedByE;\n          }\n          // "Right" face of cube\n          point = vec3(faceDistance, -pos.x, verticalCorrection*pos.y);\n\n        }\n        // Bottom left face in output image\n        else if (local_uv.x <= leftBoundary && local_uv.y < verticalBoundary) {\n          pos += vec2(2.0/3.0, 0.5);\n          if(equiAngularCubemap)  {\n            pos = tan(pos*PI/2.0)/2.0;\n            pos.x *= piDividedByE;\n          }\n          // "Top" face of cube\n          point = vec3(-pos.y*verticalCorrection, -pos.x, faceDistance);\n\n        }\n        // Bottom Middle Face in output image\n        else if (leftBoundary < local_uv.x && local_uv.x <= rightBoundary && local_uv.y < verticalBoundary) {\n          pos += vec2(0.0, 0.5);\n          if(equiAngularCubemap)  {\n            pos = tan(pos*PI/2.0)/2.0;\n            pos.x *= piDividedByE;\n          }\n          // "Back" face of cube\n          point = vec3(-pos.y*verticalCorrection, -faceDistance, -pos.x);\n\n        }\n        // Bottom Right Face in output image\n        else if (rightBoundary < local_uv.x && local_uv.y < verticalBoundary) {\n          pos += vec2(-2.0/3.0, 0.5);\n          if(equiAngularCubemap)  {\n            pos = tan(pos*PI/2.0)/2.0;\n            pos.x *= piDividedByE;\n          }\n          // "Bottom" face of cube\n          point = vec3(-pos.y*verticalCorrection, pos.x, -faceDistance);\n\n        }\n        return point;\n      }\n      // Convert a cubemap image to Latitude/Longitude Points\n      vec2 cubemapUvToLatLon(vec2 local_uv)\n      {\n        return pointToLatLon(cubemapUvToPoint(local_uv));\n      }\n\n      vec3 flatImageUvToPoint(vec2 local_uv, float fovOutput)\n      {\n        // Position of the source pixel in uv coordinates in the range [-1,1]\n        vec2 pos = 2.0 * local_uv - 1.0;\n        float aspectRatio = float(width)/float(height);\n        vec3 point = vec3(pos.x*aspectRatio, 1.0/fovOutput, pos.y);\n        point = normalize(point);\n        return point;\n      }\n      \n      vec2 flatImageUvToLatLon(vec2 local_uv, float fovOutput)\n      {\n        vec3 point = flatImageUvToPoint(local_uv, fovOutput);\n        return pointToLatLon(point);\n      }\n      \n      // Convert latitude, longitude into a 3d point on the unit-sphere.\n      vec3 flatLatLonToPoint(vec2 latLon)\n      {\n        vec3 point = latLonToPoint(latLon);\n        // Get phi of this point, see polar coordinate system for more details.\n        float phi = atan(point.x, -point.y);\n        // With phi, calculate the point on the image plane that is also at the angle phi\n        point.x = sin(phi) * tan(PI / 2.0 - latLon.x);\n        point.y = cos(phi) * tan(PI / 2.0 - latLon.x);\n        point.z = 1.0;\n        return point;\n      }\n      // Convert latitude, longitude to x, y pixel coordinates on an equirectangular image.\n      vec2 latLonToEquiUv(vec2 latLon)\n      {\n          vec2 local_uv;\n          local_uv.x = (latLon.y + PI)/(2.0*PI);\n          local_uv.y = (latLon.x + PI/2.0)/PI;\n\n          // Set to transparent if out of bounds\n          if (local_uv.x < -1.0 || local_uv.y < -1.0 || local_uv.x > 1.0 || local_uv.y > 1.0) {\n            // Return a isTransparent pixel\n            isTransparent = true;\n            return SET_TO_TRANSPARENT;\n          }\n          return local_uv;\n      }\n      \n      // Convert latitude, longitude to x, y pixel coordinates on the source fisheye image.\n      vec2 pointToFisheyeUv(vec3 point, float fovInput, vec4 fishCorrect)\n      {\t\n        point = rotatePoint(point, vec3(-PI/2.0, 0.0, 0.0));\n        // Phi and theta are flipped depending on where you read about them.\n        float theta = atan(distance(vec2(0.0,0.0),point.xy),point.z);\n        // The distance from the source pixel to the center of the image\n        float r = (2.0/PI)*(theta/fovInput);\n        \n\n        // phi is the angle of r on the unit circle. See polar coordinates for more details\n        float phi = atan(-point.y, point.x);\n        // Get the position of the source pixel\n        vec2 sourcePixel;\n        sourcePixel.x = r * cos(phi);\n        sourcePixel.y = r * sin(phi);\n        // Normalize the output pixel to be in the range [0,1]\n        sourcePixel += 1.0;\n        sourcePixel /= 2.0;\n        // Don\'t bother with source pixels outside of the fisheye circle\n        if (1.0 < r || sourcePixel.x < 0.0 || sourcePixel.y < 0.0 || sourcePixel.x > 1.0 || sourcePixel.y > 1.0) {\n          // Return a isTransparent pixel\n          isTransparent = true;\n          return SET_TO_TRANSPARENT;\n        }\n        return sourcePixel;\n      }\n      \n      bool outOfFlatBounds(vec2 xy, float lower, float upper)\n      {\n        vec2 lowerBound = vec2(lower, lower);\n        vec2 upperBound = vec2(upper, upper);\n        return (any(lessThan(xy, lowerBound)) || any(greaterThan(xy, upperBound)));\n      }\n\n\n      vec2 latLonToFlatUv(vec2 latLon, float fovInput)\n      {\n        vec3 point = rotatePoint(latLonToPoint(latLon), vec3(-PI/2.0, 0.0, 0.0));\n        latLon = pointToLatLon(point);\n        float aspectRatio = float(width)/float(height);\n\n        vec2 xyOnImagePlane;\n        vec3 p;\n        if (latLon.x < 0.0) \n        {\n          isTransparent = true;\n          return SET_TO_TRANSPARENT;\n        }\n        // Derive a 3D point on the plane which correlates with the latitude and longitude in the fisheye image.\n        p = flatLatLonToPoint(latLon);\n        p.x /= aspectRatio;\n        // Control the scale with the user\'s fov input parameter.\n        p.xy *= fovInput;\n        // Position of the source pixel in the source image in the range [-1,1]\n        xyOnImagePlane = p.xy / 2.0 + 0.5;\n        if (outOfFlatBounds(xyOnImagePlane, 0.0, 1.0)) \n    \t\t{\n          isTransparent = true;\n          return SET_TO_TRANSPARENT;\n        }\n        return xyOnImagePlane;\n      }\n\n    vec2 uvToLatLon(vec2 localUv)\n    {\n      // Given some pixel (uv), find the latitude and longitude of that pixel\n      vec2 latLon;\n      if (outputProjection == EQUI)\n        latLon = equiUvToLatLon(localUv);\n      else if(outputProjection == FISHEYE)\n      {\n        localUv.x = (localUv.x * float(width) / float(height)) - 0.5;\n        latLon = fisheyeUvToLatLon(localUv, fovOut);\n      }\n      else if (outputProjection == FLAT)\n        latLon = flatImageUvToLatLon(localUv, fovOut);\n      else if (outputProjection == CUBEMAP)\n        latLon = cubemapUvToLatLon(localUv);\n      return latLon;\n    }\n    vec3 uvToPoint(vec2 localUv)\n    {\n      return latLonToPoint(uvToLatLon(localUv));\n    }\n    // Courtesy Paul Bourke\n    // http://paulbourke.net/geometry/SolidAngle/\n    vec3 calcTangent(vec3 p0, vec3 p1)\n    {\n      vec3 p = p1 - p0;\n      vec3 r = cross(p0, p);\n      vec3 t = normalize(cross(r, p0));\n      return t;\n    }\n    \n\n    float solidAngleOfRectangle(vec3 c0, vec3 c1, vec3 c2, vec3 c3)\n    {\n      vec3 c0c1 = calcTangent(c0, c1);\n      vec3 c0c2 = calcTangent(c0, c2);\n      vec3 c1c0 = calcTangent(c1, c0);\n      vec3 c1c2 = calcTangent(c1, c2);\n      vec3 c2c0 = calcTangent(c2, c0);\n      vec3 c2c1 = calcTangent(c2, c1);\n      vec3 c0c3 = calcTangent(c0, c3);\n      vec3 c2c3 = calcTangent(c2, c3);\n      vec3 c3c0 = calcTangent(c3, c0);\n      vec3 c3c2 = calcTangent(c3, c2);\n      float theta0 = atan(length(cross(c0c2, c0c1)),dot(c0c2, c0c1)); \n      float theta1 = atan(length(cross(c1c0, c1c2)),dot(c1c0, c1c2));  \n      float theta2 = atan(length(cross(c2c1, c2c0)),dot(c2c1, c2c0));\n      float solidAngle0 = theta0 + theta1 + theta2 - PI; \n      float theta3 = atan(length(cross(c0c3, c0c2)),dot(c0c3, c0c2));  \n      float theta4 = atan(length(cross(c2c0, c2c3)),dot(c2c0, c2c3));  \n      float theta5 = atan(length(cross(c3c2, c3c0)),dot(c3c2, c3c0));\n      float solidAngle1 = theta3 + theta4 + theta5 - PI;\n      float solidAngle = solidAngle0 + solidAngle1;\n      return solidAngle;\n    }\n\n\n    float getSolidAngle(vec2 local_uv)\n    {\n      vec2 dimensions = vec2(float(width), float(height));\n      vec2 bottomLeft = uvToLatLon(local_uv + vec2(-0.5, -0.5) / dimensions);\n      vec2 topRight = uvToLatLon(local_uv + vec2(0.5, 0.5) / dimensions);\n      vec2 pixelUv = local_uv * dimensions;\n      vec3 c0 = uvToPoint((pixelUv + vec2(-1.0, -1.0)) / dimensions);\n      vec3 c1 = uvToPoint((pixelUv + vec2( 1.0, -1.0)) / dimensions);\n      vec3 c2 = uvToPoint((pixelUv + vec2( 1.0,  1.0)) / dimensions);\n      vec3 c3 = uvToPoint((pixelUv + vec2(-1.0,  1.0)) / dimensions);\n      float solidAngle = solidAngleOfRectangle(c0, c1, c2, c3);\n      // Remove outliers\n      float scalingFactor = 10000.0;\n      solidAngle *= scalingFactor;\n      return solidAngle;\n    }\n\n      void main()\n      {\n        // Display fisheye gridlines if they\'re turned on\n        if (gridLines == GRIDLINES_ON && outputProjection == FISHEYE)\n        {\n          vec2 gridlineUv = uv;\n          gridlineUv.x = (gridlineUv.x * float(width) / float(height)) - 0.5;\n          if (abs(distance(vec2(0.0, 0.0), 2.0 * gridlineUv - 1.0) - 1.0) < 0.01)\n          {\n            gl_FragColor = vec4(0.0, 0.0, 0.0, 1.0);\n            return;\n          }\n        }\n        vec3 InputRotation = vec3(pitch, roll, yaw);\n        vec4 fragColor = vec4(0.0, 0.0, 0.0, 0.0);\n        vec4 centerFragColor = vec4(0.0, 0.0, 0.0, 0.0);\n        float fovInput = fovIn;\n        float fovOutput = fovOut;\n        vec4 fishCorrect = vec4(correction1, correction2, correction3, correction4);\n        fishCorrect.xyzw -= 1.0;\n        float lineCount = 0.0;\n        // Level Of Detail: how fast should this run?\n        // Set LOD to 0 to run fast, set to 2 to blur the image, reducing jagged edges\n        const int LOD = 1;\n        //TODO Make Antialiasing a little smarter than this.\n        for(int i = -LOD; i <= LOD; i++)\n        {\n          for(int j = -LOD; j <= LOD; j++)\n          {\n            isTransparent = false;\n            vec2 uv_aa = uv + vec2(i, j)/vec2(width, height);\n\n            // Given some pixel (uv), find the latitude and longitude of that pixel\n            vec2 latLon;\n            // Create a point on the unit-sphere from the calculated latitude and longitude\n            // This sphere uses a right-handed coordinate system\n              // X increases from left to right [-1 to 1]\n              // Y increases from back to front [-1 to 1]\n              // Z increases from bottom to top [-1 to 1]\n            vec3 point;\n            if (outputProjection == EQUI)\n            {\n              latLon = equiUvToLatLon(uv_aa);\n              point = latLonToPoint(latLon);\n            }\n            else if(outputProjection == FISHEYE)\n            {\n              uv_aa.x = (uv_aa.x * float(width) / float(height)) - 0.5;\n              point = fisheyeUvToPoint(uv_aa, fovOutput);\n              // latLon = pointToLatLon(point);\n            }\n            else if (outputProjection == FLAT)\n            {\n              point = flatImageUvToPoint(uv_aa, fovOutput);\n              // latLon = pointToLatLon(point);\n            }\n            else if (outputProjection == CUBEMAP)\n            {\n              point = cubemapUvToPoint(uv_aa);\n              // latLon = pointToLatLon(point);\n            }\n            // If a pixel is out of bounds, set it to be transparent\n            if (isTransparent)\n            {\n              continue;\n            }\n            point = pointRadialCorrection(point);\n            // X, Y, Z translation inputs from the user.\n            vec3 translation = (vec3(x, y, z) - 1.0); \n            // Rotate the point based on the user input in radians\n            point.xyz += translation;\n            point = normalize(point);\n            point = rotatePoint(point, InputRotation.xyz * PI);\n            // if (distance(vec3(0.0, 0.0, 0.0), translation) > 1.0 && distance(vec3(0.0, 0.0, 0.0), point) > distance(vec3(0.0, 0.0, 0.0), translation))\n            // {\n            //   isTransparent = true;\n            //   continue;\n            // }\n            // Convert back to latitude and longitude\n            latLon = pointToLatLon(point);\n            // if (1.0 < distance(point, vec3(0.0, 0.0, 0.0)))\n            // {\n            //   // isTransparent == true;\n            //   gl_FragColor = vec4(latLon.x, latLon.y, 0.0, 1.0);\n            //   return;\n            // }\n            // Convert back to the normalized pixel coordinate\n            vec2 sourcePixel;\n            if (inputProjection == EQUI)\n              sourcePixel = latLonToEquiUv(latLon);\n            else if (inputProjection == FISHEYE)\n              sourcePixel = pointToFisheyeUv(point, fovInput, fishCorrect);\n            else if (inputProjection == FLAT)\n              sourcePixel = latLonToFlatUv(latLon, fovInput);\n\n            vec2 croppedUv = 2.0*sourcePixel-1.0;\n            float croppedWidth = cropRight - (cropLeft - 1.0);\n            float croppedHeight = cropTop - (cropBottom - 1.0);\n            // gl_FragColor = vec4(croppedWidth, 0.0, 0.0, 1.0);\n            // return;\n            croppedUv = vec2(croppedUv.x / cropRight, croppedUv.y / cropTop);\n            //float newWidth = float(width) / (croppedWidth + 1.0);\n            //float newHeight = float(newWidth) / float(height) ;\n            //croppedUv.y /= newHeight;\n            croppedUv = 0.5*croppedUv+0.5;\n            croppedUv.x += xCenter - 1.0;\n            croppedUv.y += yCenter - 1.0;\n            if (croppedUv.x < 0.0  || croppedUv.y < 0.0 || 1.0 < croppedUv.x || 1.0 < croppedUv.y)\n            {\n              continue;\n              // gl_FragColor = vec4(0.0, 0.0, 0.0, 0.0);\n              // return;\n            }\n            // If a pixel is out of bounds, set it to be transparent\n            else if (isTransparent)\n            {\n              continue;\n            }\n            if (solidAngle == 1)\n            {\n              gl_FragColor = vec4(getSolidAngle(croppedUv), 0.0, 0.0, 1.0);\n              return;\n            }\n            // Set the color of the destination pixel to the color of the source pixel\n            vec4 color = texture2D(InputTexture, croppedUv);\n\n            if (inputProjection == EQUI && gridLines == GRIDLINES_ON)\n            {\n              float minDistance = 0.3;\n              float lineThickness = minDistance;\n              for (float i = -18.0; i <= 18.0; i += 1.0)\n              {\n                float distanceToLine = abs(degrees(latLon.y) - i*10.0);\n                if (distanceToLine <= minDistance)\n                  minDistance = distanceToLine;\n                distanceToLine = abs(degrees(latLon.x) - i*10.0);\n                if (distanceToLine <= minDistance)\n                  minDistance = distanceToLine;\n              }\n              if (minDistance < lineThickness)\n              {\n                color = vec4(0.0, 0.0, 0.0, 1.0);\n                lineCount += 1.0;\n              }\n            }\n            fragColor += color;\n            if (i == 0 && j == 0)\n            {\n              // This is the aliased pixel. If we didn\'t do antialiasing this is the pixel we\'d get.\n              centerFragColor = color;\n            }\n          }\n        }\n        // antiAliasCount: how many pixels the above loop should have calculated\n        float antiAliasCount = float((1+2*LOD)*(1+2*LOD));\n        // If the pixel has any transparency (i.e. the sourcePixel is at the perimeter of the image) then do antialiasing\n        if (fragColor.a < antiAliasCount || lineCount > 0.0)\n        {\n          // Apply antialiasing. Remove the if/else statement if you want to antialias the whole image.\n          gl_FragColor = fragColor / antiAliasCount;\n          \n        }\n        else\n        {\n          // Ignore antialiasing\n          gl_FragColor = centerFragColor;\n        }\n      }\n\n    ']);return L=function(){return e},e}var E=x.Shaders.create({Reproject:{frag:Object(x.GLSL)(L())}}),T=function(e){function n(){return Object(l.a)(this,n),Object(s.a)(this,Object(p.a)(n).apply(this,arguments))}return Object(h.a)(n,e),Object(u.a)(n,[{key:"render",value:function(){var e=this.props,n=e.pitch,t=e.roll,o=e.yaw,i=e.inputProjection,r=e.fovIn,c=e.fovOut,l=e.x,s=e.y,p=e.z,u=e.correction1,h=e.correction2,v=e.correction3,d=e.correction4,f=e.cropTop,g=e.cropBottom,m=e.cropLeft,C=e.cropRight,L=e.xCenter,T=e.yCenter,P=e.outputProjection,I=e.gridLines,O=e.solidAngle,b=(e.width,e.height,e.sourceImage),A=e.test;return a.a.createElement(y.Surface,{width:1400,height:700},a.a.createElement(x.Node,{shader:E.Reproject,uniforms:{pitch:n,roll:t,yaw:o,fovIn:r,fovOut:c,x:l,y:s,z:p,correction1:u,correction2:h,correction3:v,correction4:d,cropTop:f,cropBottom:g,cropLeft:m,cropRight:C,xCenter:L,yCenter:T,inputProjection:i,outputProjection:P,gridLines:I,solidAngle:O,width:1400,height:700,InputTexture:b,test:A}}))}}]),n}(o.Component),P=t(20),I=t.n(P),O=t(16),b=t.n(O),A=(t(189),function(e){function n(e){var t;return Object(l.a)(this,n),(t=Object(s.a)(this,Object(p.a)(n).call(this,e))).state={pitch:1,roll:1,yaw:1,fovIn:1,fovOut:1,x:1,y:1,z:1,correction1:0,correction2:0,correction3:0,correction4:0,cropTop:1,cropBottom:1,cropLeft:1,cropRight:1,xCenter:1,yCenter:1,inputProjection:0,outputProjection:2,gridLines:0,solidAngle:0,pictures:[],sourceImage:"curiosity.png",name:"",uploadedImage:"",test:1,url:""},t.handleChange=function(e){var n=e.target.value;t.setState(Object(c.a)({},e.target.name,n))},t.handleUrlChange=function(e){t.setState({url:e.target.value})},t.handlePitchChange=function(e,n){t.setState({pitch:n/50})},t.handleRollChange=function(e,n){t.setState({roll:n/50})},t.handleYawChange=function(e,n){t.setState({yaw:n/50})},t.handleFovInChange=function(e,n){t.setState({fovIn:n/50})},t.handleFovOutChange=function(e,n){t.setState({fovOut:n/50})},t.handleCorrection1Change=function(e,n){t.setState({correction1:n/50})},t.handleCorrection2Change=function(e,n){t.setState({correction2:n/50})},t.handleCorrection3Change=function(e,n){t.setState({correction3:n/50})},t.handleCorrection4Change=function(e,n){t.setState({correction4:n/50})},t.handleXChange=function(e,n){t.setState({x:n/50})},t.handleYChange=function(e,n){t.setState({y:n/50})},t.handleZChange=function(e,n){t.setState({z:n/50})},t.handleSliderChange=function(e,n){t.setState(Object(c.a)({},e.target.name,e.target.value/50))},t.handleCropTopChange=function(e,n){t.setState({cropTop:n/50,cropBottom:2-n/50})},t.handleCropBottomChange=function(e,n){t.setState({cropBottom:n/50,cropTop:2-n/50})},t.handleCropLeftChange=function(e,n){t.setState({cropLeft:n/50,cropRight:2-n/50})},t.handleCropRightChange=function(e,n){t.setState({cropRight:n/50,cropLeft:2-n/50})},t.handleXCenterChange=function(e,n){t.setState({xCenter:n/50})},t.handleYCenterChange=function(e,n){t.setState({yCenter:n/50})},t.handleTestChange=function(e,n){t.setState({test:n/50})},t.onDrop=t.onDrop.bind(Object(v.a)(Object(v.a)(t))),t}return Object(h.a)(n,e),Object(u.a)(n,[{key:"handleSubmit",value:function(e){alert("A name was submitted: "+this.state.url),e.preventDefault()}}]),Object(u.a)(n,[{key:"onDrop",value:function(e){this.setState({pictures:e,uploadedImage:e[e.length-1].name,sourceImage:e[e.length-1].name})}},{key:"render",value:function(){var e=this.state,n=e.pitch,t=e.roll,o=e.yaw,i=e.fovIn,r=e.fovOut,c=e.x,l=e.y,s=e.z,p=e.correction1,u=e.correction2,h=e.correction3,v=e.correction4,d=e.cropTop,g=e.cropBottom,C=e.cropLeft,x=e.cropRight,y=e.xCenter,L=e.yCenter,E=e.inputProjection,P=e.outputProjection,O=e.gridLines,A=e.solidAngle,w=e.sourceImage,R=(e.url,e.test);return a.a.createElement("div",{className:"App-container"},a.a.createElement("div",{className:"App-slider"},a.a.createElement(f.a,{id:"outlined-name",label:"URL",className:f.a,value:this.state.url,onChange:this.handleUrlChange,margin:"normal",variant:"outlined"}),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Source Image"),a.a.createElement(I.a,{value:this.state.sourceImage,onChange:this.handleChange,inputProps:{name:"sourceImage",id:"sourceImage"}},a.a.createElement(b.a,{value:"earth.jpg"},"Earth"),a.a.createElement(b.a,{value:"test.jpg"},"Rectilinear Photo"),a.a.createElement(b.a,{value:"radial.jpg"},"Fisheye Grid"),a.a.createElement(b.a,{value:"yutu-pano2.png"},"YuTu"),a.a.createElement(b.a,{value:"curiosity.png"},"Curiosity"))),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Input Projection"),a.a.createElement(I.a,{value:this.state.inputProjection,onChange:this.handleChange,inputProps:{name:"inputProjection",id:"inputProjection"},displayEmpty:!0},a.a.createElement(b.a,{value:0},"Equirectangular"),a.a.createElement(b.a,{value:1},"Fisheye"),a.a.createElement(b.a,{value:2},"Rectilinear"))),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Output Projection"),a.a.createElement(I.a,{value:this.state.outputProjection,onChange:this.handleChange,inputProps:{name:"outputProjection",id:"outputProjection"}},a.a.createElement(b.a,{value:0},"Equirectangular"),a.a.createElement(b.a,{value:1},"Fisheye"),a.a.createElement(b.a,{value:2},"Rectilinear"),a.a.createElement(b.a,{value:3},"CubeMap"))),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Grid Lines"),a.a.createElement(I.a,{value:this.state.gridLines,onChange:this.handleChange,inputProps:{name:"gridLines",id:"gridLines"}},a.a.createElement(b.a,{value:0},"Off"),a.a.createElement(b.a,{value:1},"On"))),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Pitch: ",(180*(this.state.pitch-1)).toFixed(1)," degrees"),a.a.createElement(m.a,{value:50*n,onChange:this.handlePitchChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Roll: ",(180*(this.state.roll-1)).toFixed(1)," degrees"),a.a.createElement(m.a,{value:50*t,onChange:this.handleRollChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Yaw: ",(180*(this.state.yaw-1)).toFixed(1)," degrees"),a.a.createElement(m.a,{value:50*o,onChange:this.handleYawChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Field of View In: ",(180*this.state.fovIn).toFixed(1)," degrees"),a.a.createElement(m.a,{value:50*i,onChange:this.handleFovInChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Field of View Out: ",this.state.fovOut.toFixed(2)),a.a.createElement(m.a,{value:50*r,onChange:this.handleFovOutChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"X: ",(5*(this.state.x-1)).toFixed(1)," meters"),a.a.createElement(m.a,{value:50*c,onChange:this.handleXChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Y: ",(5*(this.state.y-1)).toFixed(1)," meters"),a.a.createElement(m.a,{value:50*l,onChange:this.handleYChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Z: ",(5*(this.state.z-1)).toFixed(1)," meters"),a.a.createElement(m.a,{value:50*s,onChange:this.handleZChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Crop Top: ",(1400*(this.state.cropTop-1)/4).toFixed(0)," pixels"),a.a.createElement(m.a,{value:50*d,onChange:this.handleCropTopChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Crop Bottom: ",(1400*(this.state.cropBottom-1)/4).toFixed(0)," pixels"),a.a.createElement(m.a,{value:50*g,onChange:this.handleCropBottomChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Crop Left  ",(1400*(this.state.cropLeft-1)/4).toFixed(0)," pixels"),a.a.createElement(m.a,{value:50*C,onChange:this.handleCropLeftChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Crop Right ",(1400*(this.state.cropRight-1)/4).toFixed(0)," pixels"),a.a.createElement(m.a,{value:50*x,onChange:this.handleCropRightChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"X Center : ",(1400*(this.state.xCenter-1)/2).toFixed(0)," pixels"),a.a.createElement(m.a,{value:50*y,onChange:this.handleXCenterChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Y Center : ",(1400*(this.state.yCenter-1)/2).toFixed(0)," pixels"),a.a.createElement(m.a,{value:50*L,onChange:this.handleYCenterChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Radial Correction 1"),a.a.createElement(f.a,{id:"correction1-box",value:this.state.correction1,onChange:this.handleChange,type:"number",inputProps:{name:"correction1"},InputLabelProps:{shrink:!0}}),a.a.createElement(m.a,{value:50*p,onChange:this.handleCorrection1Change})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Radial Correction 2"),a.a.createElement(f.a,{id:"correction2-box",value:this.state.correction2,onChange:this.handleChange,type:"number",inputProps:{name:"correction2"},InputLabelProps:{shrink:!0}}),a.a.createElement(m.a,{value:50*u,onChange:this.handleCorrection2Change})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Radial Correction 3"),a.a.createElement(f.a,{id:"correction3-box",value:this.state.correction3,onChange:this.handleChange,type:"number",inputProps:{name:"correction3"},InputLabelProps:{shrink:!0}}),a.a.createElement(m.a,{value:50*h,onChange:this.handleCorrection3Change})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Radial Correction 4"),a.a.createElement(f.a,{id:"correction4-box",value:this.state.correction4,onChange:this.handleChange,type:"number",inputProps:{name:"correction4"},InputLabelProps:{shrink:!0}}),a.a.createElement(m.a,{value:50*v,onChange:this.handleCorrection4Change})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Solid Angle per Pixel"),a.a.createElement(I.a,{value:this.state.solidAngle,onChange:this.handleChange,inputProps:{name:"solidAngle",id:"solidAngle"}},a.a.createElement(b.a,{value:0},"Off"),a.a.createElement(b.a,{value:1},"On")))),a.a.createElement("div",{className:"App-Projection"},a.a.createElement(T,{pitch:n,roll:t,yaw:o,fovIn:i,fovOut:r,x:c,y:l,z:s,xCenter:y,yCenter:L,correction1:p,correction2:u,correction3:h,correction4:v,cropTop:d,cropBottom:g,cropLeft:C,cropRight:x,inputProjection:E,outputProjection:P,gridLines:O,solidAngle:A,sourceImage:w,test:R})))}}]),n}(o.Component));Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));r.a.render(a.a.createElement(A,null),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then(function(e){e.unregister()})}},[[123,2,1]]]);
//# sourceMappingURL=main.a8ea8d5a.chunk.js.map