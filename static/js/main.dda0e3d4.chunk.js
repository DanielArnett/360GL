(window.webpackJsonp=window.webpackJsonp||[]).push([[0],{117:function(n,t,e){n.exports=e(333)},122:function(n,t,e){},124:function(n,t,e){},333:function(n,t,e){"use strict";e.r(t);var o=e(0),a=e.n(o),i=e(16),r=e.n(i),l=(e(122),e(113)),u=e(41),c=e(42),s=e(44),h=e(43),p=e(45),v=e(24),f=e.n(v),d=(e(124),e(114)),g=e(32),m=e(115);function P(){var n=Object(d.a)(["\n    // TODO turn this into its own .frag file.\n      precision highp float;\n      float PI = 3.14159265359;\n      vec2 SET_TO_TRANSPARENT = vec2(-1.0, -1.0);\n      vec4 TRANSPARENT_PIXEL = vec4(0.0, 0.0, 0.0, 0.0);\n      uniform sampler2D InputTexture;\n      uniform float pitch, roll, yaw, fovIn, fovOut;\n      uniform int inputProjection, outputProjection, width, height;\n      varying vec2 uv;\n      bool isTransparent = false;\n      const int EQUI = 0;\n      const int FISHEYE = 1;\n      const int FLAT = 2;\n      const int SPHERE = 3;\n\n      // uniform vec3 InputRotation;\n      // A transformation matrix rotating about the x axis by th degrees.\n      mat3 Rx(float th)\n      {\n          return mat3(1, 0, 0,\n                      0, cos(th), -sin(th),\n                      0, sin(th), cos(th));\n      }\n      // A transformation matrix rotating about the y axis by th degrees.\n      mat3 Ry(float th)\n      {\n          return mat3(cos(th), 0, sin(th),\n                         0,    1,    0,\n                      -sin(th), 0, cos(th));\n      }\n      // A transformation matrix rotating about the z axis by th degrees.\n      mat3 Rz(float th)\n      {\n          return mat3(cos(th), -sin(th), 0,\n                      sin(th),  cos(th), 0,\n                        0,         0   , 1);\n      }\n\n      // Rotate a point vector by th.x then th.y then th.z, and return the rotated point.\n      vec3 rotatePoint(vec3 p, vec3 th)\n      {\n        return Rx(th.x) * Ry(th.y) * Rz(th.z) * p;\n      }\n\n      // Convert a 3D point on the unit sphere into latitude and longitude.\n      vec2 pointToLatLon(vec3 point)\n      {\n        float r = distance(vec3(0.0, 0.0, 0.0), point);\n        vec2 latLon;\n        latLon.x = asin(point.z / r);\n        latLon.y = atan(point.x, point.y);\n        return latLon;\n      }\n\n      // Convert latitude, longitude into a 3d point on the unit-sphere.\n      vec3 latLonToPoint(vec2 latLon)\n      {\n          float lat = latLon.x;\n          float lon = latLon.y;\n          vec3 point;\n          point.x = cos(lat) * sin(lon);\n          point.y = cos(lat) * cos(lon);\n          point.z = sin(lat);\n          return point;\n      }\n\n      // Convert pixel coordinates from an Equirectangular image into latitude/longitude coordinates.\n      vec2 equiUvToLatLon(vec2 local_uv)\n      {\n          return vec2(local_uv.y * PI - PI/2.0,\n                      local_uv.x * 2.0*PI - PI);\n      }\n\n      // Convert  pixel coordinates from an Fisheye image into latitude/longitude coordinates.\n      vec2 fisheyeUvToLatLon(vec2 local_uv, float fovOutput)\n      {\n        vec2 pos = 2.0 * local_uv - 1.0;\n        float pixelRadius = distance(vec2(0.0,0.0),pos.xy);\n        // Don't bother with pixels outside of the fisheye circle\n        if (1.0 < pixelRadius) {\n          isTransparent = true;\n          return SET_TO_TRANSPARENT;\n        }\n        float theta = atan(pixelRadius,1.0);\n        // The distance from the source pixel to the center of the image\n        float r = theta*4.0/(PI*fovOutput);\n        // phi is the angle of r on the unit circle. See polar coordinates for more details\n        float phi = atan(pos.x,-pos.y);\n\n        vec2 latLon;\n        latLon.x = (1.0 - r)*PI/2.0;\n        // Calculate longitude\n        latLon.y = phi;\n        if (latLon.y < 0.0) {\n          latLon.y += 2.0*PI;\n        }\n        vec3 point = latLonToPoint(latLon);\n        point = rotatePoint(point, vec3(PI/2.0, 0.0, 0.0));\n        latLon = pointToLatLon(point);\n        return latLon;\n      }\n\n      vec2 sphericalUvToLatLon(vec2 local_uv)\n      {\n          // Return a isTransparent pixel\n          isTransparent = true;\n          return SET_TO_TRANSPARENT;\n      }\n      \n      vec2 flatImageUvToLatLon(vec2 local_uv, float fovOutput)\n      {\n        // Position of the source pixel in uv coordinates in the range [-1,1]\n        vec2 pos = 2.0 * local_uv - 1.0;\n        float aspectRatio = float(width)/float(height);\n        vec3 point = vec3(pos.x*aspectRatio, 1.0/fovOutput, pos.y);\n        return pointToLatLon(point);\n      }\n\n\n      \n      // Convert latitude, longitude into a 3d point on the unit-sphere.\n      vec3 flatLatLonToPoint(vec2 latLon)\n      {\n        vec3 point = latLonToPoint(latLon);\n        // Get phi of this point, see polar coordinate system for more details.\n        float phi = atan(point.x, -point.y);\n        // With phi, calculate the point on the image plane that is also at the angle phi\n        point.x = sin(phi) * tan(PI / 2.0 - latLon.x);\n        point.y = cos(phi) * tan(PI / 2.0 - latLon.x);\n        point.z = 1.0;\n        return point;\n      }\n      // Convert latitude, longitude to x, y pixel coordinates on an equirectangular image.\n      vec2 latLonToEquiUv(vec2 latLon)\n      {\n          vec2 local_uv;\n          local_uv.x = (latLon.y + PI)/(2.0*PI);\n          local_uv.y = (latLon.x + PI/2.0)/PI;\n\n          // Set to transparent if out of bounds\n          if (local_uv.x < -1.0 || local_uv.y < -1.0 || local_uv.x > 1.0 || local_uv.y > 1.0) {\n            // Return a isTransparent pixel\n            isTransparent = true;\n            return SET_TO_TRANSPARENT;\n          }\n          return local_uv;\n      }\n      \n      // Convert latitude, longitude to x, y pixel coordinates on the source fisheye image.\n      vec2 pointToFisheyeUv(vec3 point, float fovInput)\n      {\t\n        point = rotatePoint(point, vec3(-PI/2.0, 0.0, 0.0));\n        // Phi and theta are flipped depending on where you read about them.\n        float theta = atan(distance(vec2(0.0,0.0),point.xy),point.z);\n        // The distance from the source pixel to the center of the image\n        float r = theta*2.0/(PI*fovInput);\n        // phi is the angle of r on the unit circle. See polar coordinates for more details\n        float phi = atan(-point.y, point.x);\n        // Get the position of the source pixel\n        vec2 sourcePixel;\n        sourcePixel.x = r * cos(phi);\n        sourcePixel.y = r * sin(phi);\n        // Normalize the output pixel to be in the range [0,1]\n        sourcePixel += 1.0;\n        sourcePixel /= 2.0;\n        // Don't bother with source pixels outside of the fisheye circle\n        if (1.0 < r || sourcePixel.x < 0.0 || sourcePixel.y < 0.0 || sourcePixel.x > 1.0 || sourcePixel.y > 1.0) {\n          // Return a isTransparent pixel\n          isTransparent = true;\n          return SET_TO_TRANSPARENT;\n        }\n        return sourcePixel;\n      }\n      \n      bool outOfFlatBounds(vec2 xy, float lower, float upper)\n      {\n        vec2 lowerBound = vec2(lower, lower);\n        vec2 upperBound = vec2(upper, upper);\n        return (any(lessThan(xy, lowerBound)) || any(greaterThan(xy, upperBound)));\n      }\n      vec2 latLonToFlatUv(vec2 latLon, float fovInput)\n      {\n        vec3 point = rotatePoint(latLonToPoint(latLon), vec3(-PI/2.0, 0.0, 0.0));\n        latLon = pointToLatLon(point);\n        float aspectRatio = float(width)/float(height);\n\n        vec2 xyOnImagePlane;\n        vec3 p;\n        if (latLon.x < 0.0) \n        {\n          isTransparent = true;\n          return SET_TO_TRANSPARENT;\n        }\n        // Derive a 3D point on the plane which correlates with the latitude and longitude in the fisheye image.\n        p = flatLatLonToPoint(latLon);\n        p.x /= aspectRatio;\n        // Control the scale with the user's fov input parameter.\n        p.xy *= fovInput;\n        // Position of the source pixel in the source image in the range [-1,1]\n        xyOnImagePlane = p.xy / 2.0 + 0.5;\n        if (outOfFlatBounds(xyOnImagePlane, 0.0, 1.0)) \n    \t\t{\n          isTransparent = true;\n          return SET_TO_TRANSPARENT;\n        }\n        return xyOnImagePlane;\n      }\n      void main()\n      {\n        vec3 InputRotation = vec3(pitch, roll, yaw);\n        vec4 fragColor = vec4(0.0, 0.0, 0.0, 0.0);\n        vec4 centerFragColor = vec4(0.0, 0.0, 0.0, 0.0);\n        float fovInput = fovIn;\n        float fovOutput = fovOut;\n        // Level Of Detail: how fast should this run?\n        // Set LOD to 0 to run fast, set to two to blur the image, reducing jagged edges\n        const int LOD = 1;\n        //TODO Make Antialiasing a little smarter than this.\n        for(int i = -LOD; i <= LOD; i++)\n        {\n          for(int j = -LOD; j <= LOD; j++)\n          {\n            isTransparent = false;\n            vec2 uv_aa = uv + vec2(i, j)/vec2(width, height);\n            // Given some pixel (uv), find the latitude and longitude of that pixel\n            vec2 latLon;\n            if (outputProjection == EQUI)\n              latLon = equiUvToLatLon(uv_aa);\n            else if(outputProjection == FISHEYE)\n              latLon = fisheyeUvToLatLon(uv_aa, fovOutput);\n            else if (outputProjection == FLAT)\n              latLon = flatImageUvToLatLon(uv_aa, fovOutput);\n            else if (outputProjection == SPHERE)\n              latLon = sphericalUvToLatLon(uv_aa);\n            // If a pixel is out of bounds, set it to be transparent\n            if (isTransparent)\n            {\n              continue;\n            }\n            // Create a point on the unit-sphere from the calculated latitude and longitude\n            // This sphere uses a right-handed coordinate system\n              // X increases from left to right [-1 to 1]\n              // Y increases from back to front [-1 to 1]\n              // Z increases from bottom to top [-1 to 1]\n            vec3 point = latLonToPoint(latLon);\n            // Rotate the point based on the user input in radians\n            point = rotatePoint(point, InputRotation.rgb * PI);\n            // Convert back to latitude and longitude\n            latLon = pointToLatLon(point);\n            \n            // Convert back to the normalized pixel coordinate\n            vec2 sourcePixel;\n            if (inputProjection == EQUI)\n              sourcePixel = latLonToEquiUv(latLon);\n            else if (inputProjection == FISHEYE)\n              sourcePixel = pointToFisheyeUv(point, fovInput);\n            else if (inputProjection == FLAT)\n              sourcePixel = latLonToFlatUv(latLon, fovInput);\n            // If a pixel is out of bounds, set it to be transparent\n            if (isTransparent)\n            {\n              continue;\n            }\n            // Set the color of the destination pixel to the color of the source pixel\n            vec4 color = texture2D(InputTexture, sourcePixel);\n            fragColor += color;\n            if (i == 0 && j == 0)\n            {\n              // This is the aliased pixel. If we didn't do antialiasing this is the pixel we'd get.\n              centerFragColor = color;\n            }\n          }\n        }\n        // antiAliasCount: how many pixels the above loop should have calculated\n        float antiAliasCount = float((1+2*LOD)*(1+2*LOD));\n        // If the pixel has any transparency (i.e. the sourcePixel is at the perimeter of the image) then do antialiasing\n        if (fragColor.a < antiAliasCount)\n        {\n          // Apply antialiasing. Remove the if/else statement if you want to antialias the whole image.\n          gl_FragColor = fragColor / antiAliasCount;\n          \n        }\n        else\n        {\n          // Ignore antialiasing\n          gl_FragColor = centerFragColor;\n        }\n      }\n\n    "]);return P=function(){return n},n}var x=g.Shaders.create({Saturate:{frag:Object(g.GLSL)(P())}}),L=function(n){function t(){return Object(u.a)(this,t),Object(s.a)(this,Object(h.a)(t).apply(this,arguments))}return Object(p.a)(t,n),Object(c.a)(t,[{key:"render",value:function(){var n=this.props,t=n.pitch,e=n.roll,o=n.yaw,i=n.inputProjection,r=n.fovIn,l=n.fovOut,u=n.outputProjection,c=(n.width,n.height,n.sourceImage);return a.a.createElement(m.Surface,{width:1200,height:600},a.a.createElement(g.Node,{shader:x.Saturate,uniforms:{pitch:t,roll:e,yaw:o,fovIn:r,fovOut:l,inputProjection:i,outputProjection:u,width:1200,height:600,InputTexture:c}}))}}]),t}(o.Component),T=e(47),y=e.n(T),E=e(46),I=e.n(E),O=e(17),j=e.n(O),w=function(n){function t(){var n,e;Object(u.a)(this,t);for(var o=arguments.length,a=new Array(o),i=0;i<o;i++)a[i]=arguments[i];return(e=Object(s.a)(this,(n=Object(h.a)(t)).call.apply(n,[this].concat(a)))).state={pitch:1,roll:1,yaw:1,fovIn:1,fovOut:1,inputProjection:0,outputProjection:0,sourceImage:"earth.jpg",name:""},e.handleProjectionChange=function(n,t){e.setState({inputProjection:t})},e.handleChange=function(n){e.setState(Object(l.a)({},n.target.name,n.target.value))},e.handlePitchChange=function(n,t){e.setState({pitch:t/50})},e.handleRollChange=function(n,t){e.setState({roll:t/50})},e.handleYawChange=function(n,t){e.setState({yaw:t/50})},e.handleFovInChange=function(n,t){e.setState({fovIn:t/50})},e.handleFovOutChange=function(n,t){e.setState({fovOut:t/50})},e}return Object(p.a)(t,n),Object(c.a)(t,[{key:"render",value:function(){var n=this.state,t=n.pitch,e=n.roll,o=n.yaw,i=n.fovIn,r=n.fovOut,l=n.inputProjection,u=n.outputProjection,c=n.sourceImage;return a.a.createElement("div",{className:"App-container"},a.a.createElement("div",{className:"App-slider"},a.a.createElement("div",{className:"Source-image-selecter"},a.a.createElement(I.a,{htmlFor:"sourceImage"},"Source Image"),a.a.createElement(y.a,{value:this.sourceImage,onChange:this.handleChange,inputProps:{name:"sourceImage",id:"sourceImage"}},a.a.createElement(j.a,{value:"earth.jpg"},"Earth"),a.a.createElement(j.a,{value:"earth_8k.jpg"},"Earth 8k"),a.a.createElement(j.a,{value:"radial.jpg"},"Fisheye Grid"),a.a.createElement(j.a,{value:"bourke_sphericalpano.jpg"},"360 Photo"))),a.a.createElement(I.a,{shrink:!0,htmlFor:"inputProjection"},"Input Projection"),a.a.createElement(y.a,{value:this.inputProjection,onChange:this.handleChange,inputProps:{name:"inputProjection",id:"inputProjection"},displayEmpty:!0},a.a.createElement(j.a,{value:0},"Equirectangular"),a.a.createElement(j.a,{value:1},"Fisheye"),a.a.createElement(j.a,{value:2},"Rectilinear")),a.a.createElement(I.a,{htmlFor:"outputProjection"},"Output Projection"),a.a.createElement(y.a,{value:this.outputProjection,onChange:this.handleChange,inputProps:{name:"outputProjection",id:"outputProjection"}},a.a.createElement(j.a,{value:0},"Equirectangular"),a.a.createElement(j.a,{value:1},"Fisheye"),a.a.createElement(j.a,{value:2},"Rectilinear"),a.a.createElement(j.a,{value:3},"Sphere")),a.a.createElement("p",null,"Pitch"),a.a.createElement(f.a,{value:50*t,onChange:this.handlePitchChange}),a.a.createElement("p",null,"Roll"),a.a.createElement(f.a,{value:50*e,onChange:this.handleRollChange}),a.a.createElement("p",null,"Yaw"),a.a.createElement(f.a,{value:50*o,onChange:this.handleYawChange}),a.a.createElement("p",null,"Field of View In"),a.a.createElement(f.a,{value:50*i,onChange:this.handleFovInChange}),a.a.createElement("p",null,"Field of View Out"),a.a.createElement(f.a,{value:50*r,onChange:this.handleFovOutChange})),a.a.createElement("div",{className:"App-Projection"},a.a.createElement(L,{pitch:t,roll:e,yaw:o,fovIn:i,fovOut:r,inputProjection:l,outputProjection:u,sourceImage:c})))}}]),t}(o.Component);Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));r.a.render(a.a.createElement(w,null),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then(function(n){n.unregister()})}},[[117,2,1]]]);
//# sourceMappingURL=main.dda0e3d4.chunk.js.map