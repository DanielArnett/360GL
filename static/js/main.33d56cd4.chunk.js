(window.webpackJsonp=window.webpackJsonp||[]).push([[0],{119:function(e,n,t){e.exports=t(339)},124:function(e,n,t){},126:function(e,n,t){},339:function(e,n,t){"use strict";t.r(n);var o=t(0),a=t.n(o),i=t(15),r=t.n(i),l=(t(124),t(59)),c=t(44),s=t(45),u=t(47),h=t(46),p=t(48),v=t(32),f=t(18),d=t.n(f),m=(t(126),t(115)),g=t(33),L=t(116);function x(){var e=Object(m.a)(["\n    // TODO turn this into its own .frag file.\n      precision highp float;\n      float PI = 3.14159265359;\n      vec2 SET_TO_TRANSPARENT = vec2(-1.0, -1.0);\n      vec4 TRANSPARENT_PIXEL = vec4(0.0, 0.0, 0.0, 0.0);\n      bool FISHEYE_RADIAL_CORRECTION = true;\n      uniform float correction1, correction2, correction3, correction4;\n      uniform sampler2D InputTexture;\n      uniform float pitch, roll, yaw, fovIn, fovOut, x, y, z;\n      uniform int inputProjection, outputProjection, gridLines, width, height;\n      varying vec2 uv;\n      bool isTransparent = false;\n      const int EQUI = 0;\n      const int FISHEYE = 1;\n      const int FLAT = 2;\n      const int SPHERE = 3;\n      const int GRIDLINES_OFF = 0;\n      const int GRIDLINES_ON = 1;\n\n      // uniform vec3 InputRotation;\n      // A transformation matrix rotating about the x axis by th degrees.\n      mat3 Rx(float th)\n      {\n          return mat3(1, 0, 0,\n                      0, cos(th), -sin(th),\n                      0, sin(th), cos(th));\n      }\n      // A transformation matrix rotating about the y axis by th degrees.\n      mat3 Ry(float th)\n      {\n          return mat3(cos(th), 0, sin(th),\n                         0,    1,    0,\n                      -sin(th), 0, cos(th));\n      }\n      // A transformation matrix rotating about the z axis by th degrees.\n      mat3 Rz(float th)\n      {\n          return mat3(cos(th), -sin(th), 0,\n                      sin(th),  cos(th), 0,\n                        0,         0   , 1);\n      }\n\n      // Rotate a point vector by th.x then th.y then th.z, and return the rotated point.\n      vec3 rotatePoint(vec3 p, vec3 th)\n      {\n        return Rx(th.x) * Ry(th.y) * Rz(th.z) * p;\n      }\n\n      // Convert a 3D point on the unit sphere into latitude and longitude.\n      vec2 pointToLatLon(vec3 point)\n      {\n        float r = distance(vec3(0.0, 0.0, 0.0), point);\n        vec2 latLon;\n        latLon.x = asin(point.z / r);\n        latLon.y = atan(point.x, point.y);\n        return latLon;\n      }\n\n      // Convert latitude, longitude into a 3d point on the unit-sphere.\n      vec3 latLonToPoint(vec2 latLon)\n      {\n          float lat = latLon.x;\n          float lon = latLon.y;\n          vec3 point;\n          point.x = cos(lat) * sin(lon);\n          point.y = cos(lat) * cos(lon);\n          point.z = sin(lat);\n          return point;\n      }\n\n      // Convert pixel coordinates from an Equirectangular image into latitude/longitude coordinates.\n      vec2 equiUvToLatLon(vec2 local_uv)\n      {\n          return vec2(local_uv.y * PI - PI/2.0,\n                      local_uv.x * 2.0*PI - PI);\n      }\n\n      // Convert  pixel coordinates from an Fisheye image into latitude/longitude coordinates.\n      vec2 fisheyeUvToLatLon(vec2 local_uv, float fovOutput)\n      {\n        vec2 pos = 2.0 * local_uv - 1.0;\n        float pixelRadius = distance(vec2(0.0,0.0),pos.xy);\n        // Don't bother with pixels outside of the fisheye circle\n        if (1.0 < pixelRadius) {\n          isTransparent = true;\n          return SET_TO_TRANSPARENT;\n        }\n        float theta = atan(pixelRadius,1.0);\n        // phi is the angle of r on the unit circle. See polar coordinates for more details\n        float phi = atan(pos.x,-pos.y);\n        // The distance from the source pixel to the center of the image\n        float r = (4.0/PI)*theta/fovOutput;\n        \n        vec2 latLon;\n        latLon.x = (1.0 - r)*PI/2.0;\n        // Calculate longitude\n        latLon.y = phi;\n        if (latLon.y < 0.0) {\n          latLon.y += 2.0*PI;\n        }\n        vec3 point = latLonToPoint(latLon);\n        point = rotatePoint(point, vec3(PI/2.0, 0.0, 0.0));\n        latLon = pointToLatLon(point);\n        return latLon;\n      }\n\n      vec2 sphericalUvToLatLon(vec2 local_uv)\n      {\n          // Return a isTransparent pixel\n          isTransparent = true;\n          return SET_TO_TRANSPARENT;\n      }\n      \n      vec2 flatImageUvToLatLon(vec2 local_uv, float fovOutput)\n      {\n        // Position of the source pixel in uv coordinates in the range [-1,1]\n        vec2 pos = 2.0 * local_uv - 1.0;\n        float aspectRatio = float(width)/float(height);\n        vec3 point = vec3(pos.x*aspectRatio, 1.0/fovOutput, pos.y);\n        return pointToLatLon(point);\n      }\n\n\n      \n      // Convert latitude, longitude into a 3d point on the unit-sphere.\n      vec3 flatLatLonToPoint(vec2 latLon)\n      {\n        vec3 point = latLonToPoint(latLon);\n        // Get phi of this point, see polar coordinate system for more details.\n        float phi = atan(point.x, -point.y);\n        // With phi, calculate the point on the image plane that is also at the angle phi\n        point.x = sin(phi) * tan(PI / 2.0 - latLon.x);\n        point.y = cos(phi) * tan(PI / 2.0 - latLon.x);\n        point.z = 1.0;\n        return point;\n      }\n      // Convert latitude, longitude to x, y pixel coordinates on an equirectangular image.\n      vec2 latLonToEquiUv(vec2 latLon)\n      {\n          vec2 local_uv;\n          local_uv.x = (latLon.y + PI)/(2.0*PI);\n          local_uv.y = (latLon.x + PI/2.0)/PI;\n\n          // Set to transparent if out of bounds\n          if (local_uv.x < -1.0 || local_uv.y < -1.0 || local_uv.x > 1.0 || local_uv.y > 1.0) {\n            // Return a isTransparent pixel\n            isTransparent = true;\n            return SET_TO_TRANSPARENT;\n          }\n          return local_uv;\n      }\n      \n      // Convert latitude, longitude to x, y pixel coordinates on the source fisheye image.\n      vec2 pointToFisheyeUv(vec3 point, float fovInput, vec4 fishCorrect)\n      {\t\n        point = rotatePoint(point, vec3(-PI/2.0, 0.0, 0.0));\n        // Phi and theta are flipped depending on where you read about them.\n        float theta = atan(distance(vec2(0.0,0.0),point.xy),point.z);\n        // The distance from the source pixel to the center of the image\n        float r = (2.0/PI)*(theta/fovInput);\n        if (FISHEYE_RADIAL_CORRECTION)\n        {\n          // Do radial correction. \n          // Source: http://paulbourke.net/dome/fisheyecorrect/\n          r *= 2.0 * (fishCorrect.x + theta * (fishCorrect.y + theta * (fishCorrect.z + theta * fishCorrect.w)));\n        }\n        // phi is the angle of r on the unit circle. See polar coordinates for more details\n        float phi = atan(-point.y, point.x);\n        // Get the position of the source pixel\n        vec2 sourcePixel;\n        sourcePixel.x = r * cos(phi);\n        sourcePixel.y = r * sin(phi);\n        // Normalize the output pixel to be in the range [0,1]\n        sourcePixel += 1.0;\n        sourcePixel /= 2.0;\n        // Don't bother with source pixels outside of the fisheye circle\n        if (1.0 < r || sourcePixel.x < 0.0 || sourcePixel.y < 0.0 || sourcePixel.x > 1.0 || sourcePixel.y > 1.0) {\n          // Return a isTransparent pixel\n          isTransparent = true;\n          return SET_TO_TRANSPARENT;\n        }\n        return sourcePixel;\n      }\n      \n      bool outOfFlatBounds(vec2 xy, float lower, float upper)\n      {\n        vec2 lowerBound = vec2(lower, lower);\n        vec2 upperBound = vec2(upper, upper);\n        return (any(lessThan(xy, lowerBound)) || any(greaterThan(xy, upperBound)));\n      }\n      vec2 latLonToFlatUv(vec2 latLon, float fovInput)\n      {\n        vec3 point = rotatePoint(latLonToPoint(latLon), vec3(-PI/2.0, 0.0, 0.0));\n        latLon = pointToLatLon(point);\n        float aspectRatio = float(width)/float(height);\n\n        vec2 xyOnImagePlane;\n        vec3 p;\n        if (latLon.x < 0.0) \n        {\n          isTransparent = true;\n          return SET_TO_TRANSPARENT;\n        }\n        // Derive a 3D point on the plane which correlates with the latitude and longitude in the fisheye image.\n        p = flatLatLonToPoint(latLon);\n        p.x /= aspectRatio;\n        // Control the scale with the user's fov input parameter.\n        p.xy *= fovInput;\n        // Position of the source pixel in the source image in the range [-1,1]\n        xyOnImagePlane = p.xy / 2.0 + 0.5;\n        if (outOfFlatBounds(xyOnImagePlane, 0.0, 1.0)) \n    \t\t{\n          isTransparent = true;\n          return SET_TO_TRANSPARENT;\n        }\n        return xyOnImagePlane;\n      }\n      void main()\n      {\n        vec3 InputRotation = vec3(pitch, roll, yaw);\n        vec4 fragColor = vec4(0.0, 0.0, 0.0, 0.0);\n        vec4 centerFragColor = vec4(0.0, 0.0, 0.0, 0.0);\n        float fovInput = fovIn;\n        float fovOutput = fovOut;\n        vec4 fishCorrect = vec4(correction1-0.5, correction2, correction3, correction4);\n        fishCorrect.yzw -= 1.0;\n        float lineCount = 0.0;\n        // Level Of Detail: how fast should this run?\n        // Set LOD to 0 to run fast, set to two to blur the image, reducing jagged edges\n        const int LOD = 1;\n        //TODO Make Antialiasing a little smarter than this.\n        for(int i = -LOD; i <= LOD; i++)\n        {\n          for(int j = -LOD; j <= LOD; j++)\n          {\n            isTransparent = false;\n            vec2 uv_aa = uv + vec2(i, j)/vec2(width, height);\n            // Given some pixel (uv), find the latitude and longitude of that pixel\n            vec2 latLon;\n            if (outputProjection == EQUI)\n              latLon = equiUvToLatLon(uv_aa);\n            else if(outputProjection == FISHEYE)\n            {\n              uv_aa.x = (uv_aa.x * float(width) / float(height)) - 0.5;\n              latLon = fisheyeUvToLatLon(uv_aa, fovOutput);\n            }\n            else if (outputProjection == FLAT)\n              latLon = flatImageUvToLatLon(uv_aa, fovOutput);\n            else if (outputProjection == SPHERE)\n              latLon = sphericalUvToLatLon(uv_aa);\n            // If a pixel is out of bounds, set it to be transparent\n            if (isTransparent)\n            {\n              continue;\n            }\n            // Create a point on the unit-sphere from the calculated latitude and longitude\n            // This sphere uses a right-handed coordinate system\n              // X increases from left to right [-1 to 1]\n              // Y increases from back to front [-1 to 1]\n              // Z increases from bottom to top [-1 to 1]\n            vec3 point = latLonToPoint(latLon);\n            // X, Y, Z translation inputs from the user.\n            point.xyz += vec3(x, y, z) - 1.0;\n            // Rotate the point based on the user input in radians\n            point = rotatePoint(point, InputRotation.rgb * PI);\n            // Convert back to latitude and longitude\n            latLon = pointToLatLon(point);\n            \n            // Convert back to the normalized pixel coordinate\n            vec2 sourcePixel;\n            if (inputProjection == EQUI)\n              sourcePixel = latLonToEquiUv(latLon);\n            else if (inputProjection == FISHEYE)\n              sourcePixel = pointToFisheyeUv(point, fovInput, fishCorrect);\n            else if (inputProjection == FLAT)\n              sourcePixel = latLonToFlatUv(latLon, fovInput);\n            // If a pixel is out of bounds, set it to be transparent\n            if (isTransparent)\n            {\n              continue;\n            }\n            // Set the color of the destination pixel to the color of the source pixel\n            vec4 color = texture2D(InputTexture, sourcePixel);\n\n            if (inputProjection == EQUI && gridLines == GRIDLINES_ON)\n            {\n              float minDistance = 0.3;\n              float lineThickness = minDistance;\n              for (float i = -18.0; i <= 18.0; i += 1.0)\n              {\n                float distanceToLine = abs(degrees(latLon.y) - i*10.0);\n                if (distanceToLine <= minDistance)\n                  minDistance = distanceToLine;\n                distanceToLine = abs(degrees(latLon.x) - i*10.0);\n                if (distanceToLine <= minDistance)\n                  minDistance = distanceToLine;\n              }\n              if (minDistance < lineThickness)\n              {\n                color = vec4(0.0, 0.0, 0.0, 1.0);\n                lineCount += 1.0;\n              }\n            }\n            fragColor += color;\n            if (i == 0 && j == 0)\n            {\n              // This is the aliased pixel. If we didn't do antialiasing this is the pixel we'd get.\n              centerFragColor = color;\n            }\n          }\n        }\n        // antiAliasCount: how many pixels the above loop should have calculated\n        float antiAliasCount = float((1+2*LOD)*(1+2*LOD));\n        // If the pixel has any transparency (i.e. the sourcePixel is at the perimeter of the image) then do antialiasing\n        if (fragColor.a < antiAliasCount || lineCount > 0.0)\n        {\n          // Apply antialiasing. Remove the if/else statement if you want to antialias the whole image.\n          gl_FragColor = fragColor / antiAliasCount;\n          \n        }\n        else\n        {\n          // Ignore antialiasing\n          gl_FragColor = centerFragColor;\n        }\n      }\n\n    "]);return x=function(){return e},e}var E=g.Shaders.create({Reproject:{frag:Object(g.GLSL)(x())}}),P=function(e){function n(){return Object(c.a)(this,n),Object(u.a)(this,Object(h.a)(n).apply(this,arguments))}return Object(p.a)(n,e),Object(s.a)(n,[{key:"render",value:function(){var e=this.props,n=e.pitch,t=e.roll,o=e.yaw,i=e.inputProjection,r=e.fovIn,l=e.fovOut,c=e.x,s=e.y,u=e.z,h=e.correction1,p=e.correction2,v=e.correction3,f=e.correction4,d=e.outputProjection,m=e.gridLines,x=(e.width,e.height,e.sourceImage);return a.a.createElement(L.Surface,{width:1400,height:700},a.a.createElement(g.Node,{shader:E.Reproject,uniforms:{pitch:n,roll:t,yaw:o,fovIn:r,fovOut:l,x:c,y:s,z:u,correction1:h,correction2:p,correction3:v,correction4:f,inputProjection:i,outputProjection:d,gridLines:m,width:1400,height:700,InputTexture:x}}))}}]),n}(o.Component),y=t(35),T=t.n(y),I=t(34),C=t.n(I),O=t(16),j=t.n(O),w=t(117),R=t.n(w),S=function(e){function n(e){var t;return Object(c.a)(this,n),(t=Object(u.a)(this,Object(h.a)(n).call(this,e))).state={pitch:1,roll:1,yaw:1,fovIn:1,fovOut:1,x:1,y:1,z:1,correction1:1,correction2:1,correction3:1,correction4:1,inputProjection:0,outputProjection:0,gridLines:0,pictures:[],sourceImage:"earth.jpg",name:"",uploadedImage:""},t.handleProjectionChange=function(e,n){t.setState({inputProjection:n})},t.handleChange=function(e){t.setState(Object(l.a)({},e.target.name,e.target.value))},t.handlePitchChange=function(e,n){t.setState({pitch:n/50})},t.handleRollChange=function(e,n){t.setState({roll:n/50})},t.handleYawChange=function(e,n){t.setState({yaw:n/50})},t.handleFovInChange=function(e,n){t.setState({fovIn:n/50})},t.handleFovOutChange=function(e,n){t.setState({fovOut:n/50})},t.handleCorrection1Change=function(e,n){t.setState({correction1:n/50})},t.handleCorrection2Change=function(e,n){t.setState({correction2:n/50})},t.handleCorrection3Change=function(e,n){t.setState({correction3:n/50})},t.handleCorrection4Change=function(e,n){t.setState({correction4:n/50})},t.handleXChange=function(e,n){t.setState({x:n/50})},t.handleYChange=function(e,n){t.setState({y:n/50})},t.handleZChange=function(e,n){t.setState({z:n/50})},t.handleSliderChange=function(e,n){t.setState(Object(l.a)({},e.target.name,e.target.value/50))},t.onDrop=t.onDrop.bind(Object(v.a)(Object(v.a)(t))),t}return Object(p.a)(n,e),Object(s.a)(n,[{key:"onDrop",value:function(e){this.setState({pictures:e,uploadedImage:e[e.length-1].name,sourceImage:e[e.length-1].name})}},{key:"render",value:function(){var e=this.state,n=e.pitch,t=e.roll,o=e.yaw,i=e.fovIn,r=e.fovOut,l=e.x,c=e.y,s=e.z,u=e.correction1,h=e.correction2,p=e.correction3,v=e.correction4,f=e.inputProjection,m=e.outputProjection,g=e.gridLines,L=e.sourceImage;return a.a.createElement("div",{className:"App-container"},a.a.createElement("div",{className:"App-slider"},a.a.createElement("div",{className:"App-Options"},a.a.createElement(R.a,{withIcon:!0,buttonText:"Choose image",onChange:this.onDrop,imgExtension:[".jpg",".gif",".png",".gif"],maxFileSize:5242880,singleImage:!0,withPreview:!1})),a.a.createElement("div",{className:"App-Options"},a.a.createElement(C.a,{htmlFor:"sourceImage"},"Source Image"),a.a.createElement(T.a,{value:this.sourceImage,onChange:this.handleChange,inputProps:{name:"sourceImage",id:"sourceImage"}},a.a.createElement(j.a,{value:"earth.jpg"},"Earth"),a.a.createElement(j.a,{value:"earth_8k.jpg"},"Earth 8k"),a.a.createElement(j.a,{value:"radial.jpg"},"Fisheye Grid"),a.a.createElement(j.a,{value:"bourke_sphericalpano.jpg"},"360 Photo"),a.a.createElement(j.a,{value:this.state.uploadedImage},this.state.uploadedImage))),a.a.createElement("div",{className:"App-Options"},a.a.createElement(C.a,{shrink:!0,htmlFor:"inputProjection"},"Input Projection"),a.a.createElement(T.a,{value:this.inputProjection,onChange:this.handleChange,inputProps:{name:"inputProjection",id:"inputProjection"},displayEmpty:!0},a.a.createElement(j.a,{value:0},"Equirectangular"),a.a.createElement(j.a,{value:1},"Fisheye"),a.a.createElement(j.a,{value:2},"Rectilinear"))),a.a.createElement("div",{className:"App-Options"},a.a.createElement(C.a,{htmlFor:"outputProjection"},"Output Projection"),a.a.createElement(T.a,{value:this.outputProjection,onChange:this.handleChange,inputProps:{name:"outputProjection",id:"outputProjection"}},a.a.createElement(j.a,{value:0},"Equirectangular"),a.a.createElement(j.a,{value:1},"Fisheye"),a.a.createElement(j.a,{value:2},"Rectilinear"),a.a.createElement(j.a,{value:3},"Sphere"))),a.a.createElement("div",{className:"App-Options"},a.a.createElement(C.a,{htmlFor:"gridLines"},"Grid Lines"),a.a.createElement(T.a,{value:this.gridLines,onChange:this.handleChange,inputProps:{name:"gridLines",id:"gridLines"}},a.a.createElement(j.a,{value:0},"Off"),a.a.createElement(j.a,{value:1},"On"))),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Pitch"),a.a.createElement(d.a,{value:50*n,onChange:this.handlePitchChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Roll"),a.a.createElement(d.a,{value:50*t,onChange:this.handleRollChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Yaw"),a.a.createElement(d.a,{value:50*o,onChange:this.handleYawChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Field of View In"),a.a.createElement(d.a,{value:50*i,onChange:this.handleFovInChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Field of View Out"),a.a.createElement(d.a,{value:50*r,onChange:this.handleFovOutChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"X"),a.a.createElement(d.a,{value:50*l,onChange:this.handleXChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Y"),a.a.createElement(d.a,{value:50*c,onChange:this.handleYChange})),a.a.createElement("div",{className:"App-Options"},a.a.createElement("p",null,"Z"),a.a.createElement(d.a,{value:50*s,onChange:this.handleZChange}))),a.a.createElement("div",{className:"App-Projection"},a.a.createElement(P,{pitch:n,roll:t,yaw:o,fovIn:i,fovOut:r,x:l,y:c,z:s,correction1:u,correction2:h,correction3:p,correction4:v,inputProjection:f,outputProjection:m,gridLines:g,sourceImage:L})))}}]),n}(o.Component);Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));r.a.render(a.a.createElement(S,null),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then(function(e){e.unregister()})}},[[119,2,1]]]);
//# sourceMappingURL=main.33d56cd4.chunk.js.map